---
title: "Portfolio Computational Musicology"
author: "Eliza"
date: "spring 2023"
output: 
  flexdashboard::flex_dashboard:
    self_contained: false
    theme: flatly
    vertical_layout: fill
    horizontal_layout: scroll
---

```{r}
library(tidyverse)
library(spotifyr)
library(compmus)
library(plotly)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(cowplot)
```

```{r}
Top1999 <- get_playlist_audio_features("", "0qSHbyaiZbhacDdIegMoBR")
Top2009 <- get_playlist_audio_features("", "6BJbzcSvOunQpVCJuBLxEW")
Top2019 <- get_playlist_audio_features("", "1MaaUHHVuXbmrDhoUCDDcL")
Top2022 <- get_playlist_audio_features("", "4U5UXciYphLDZAIgjdz50v")

Top2000lists <-
  bind_rows(
    Top1999 |> mutate(category = "1999"),
    Top2009 |> mutate(category = "2009"),
    Top2019 |> mutate(category = "2019"),
    Top2022 |> mutate(category = "2022")
  )
```

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

What is the TOP2000?
===================================================

Column {data-width=500}
---------------------------------------------------

### What is the TOP2000?

**"The list of lists"**

The TOP2000 is a Dutch radio programme by radio station NPO radio 2. From Christmas Day until midnight of New Year's Eve, a list of 2000 songs that are considered the "most popular songs of all time", is broadcasted. The list, constructed by votes from the audience, was first on air in 1999 to celebrate the new millennium. Due to the success of the show, the radio station decided to make it an annual programme. In the following years, the TOP2000 grew out to become a yearly tradition for many households.

The list of 2000 songs has changed over the years with new songs entering the TOP2000 and other songs not making it to the final cut. New generations of kids grew up listening to the show with their parents and are voting on their favourite songs now too. More recent hits are making it to the list every year (see statistics [here](https://www.nporadio2.nl/top2000/statistieken)) and most likely making the list conform to its time. What exactly are the differences between the list throughout the years and has the sound of the TOP2000 changed over the past 23 years?


**The TOP2000 of 1999, 2009, 2019 and 2022**

The corpus consists of four playlists: the TOP2000 list from 1999, 2009, 2019 and 2022. The 2000 songs that should be included can be found on the NPO radio 2 [website](https://www.nporadio2.nl/top2000). I am using two already existing playlists on Spotify that I have checked on accuracy, the other two playlists I have created myself. Even though the playlists are carefully constructed, there are a few songs missing. This is not the fault of the creator, Spotify simply doesn't have the songs in its library. This results in the list from 1999 containing a total of 1976 songs, 2009 has 1982 songs, the list from 2019 contains 1993 songs and 2022 has the most with 1999 songs. The amount of songs missing is limited and should therefore not cause too many problems for the data analysis.

An example of a song that is remarkable in the TOP2000 is Danny Vera's Roller Coaster. The song entered the list in 2019, immediately making it to the 4th place. Ever since, it has been in the top 3 which has not happened with other songs before. If we look at the TOP2000 of 1999 it is interesting to see that Avond by Boudewijn de Groot was only placed at 428. The song has grown in popularity because it now has positioned itself on the 8th place. I expect that newly released songs like Roller Coaster and songs gaining a lot more popularity over time like for example Avond have changed the general sound of the TOP2000 over its years. 

Column {data-width=250}
---------------------------------------------------

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/0qSHbyaiZbhacDdIegMoBR?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6BJbzcSvOunQpVCJuBLxEW?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Column {data-width=250}
---------------------------------------------------

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/1MaaUHHVuXbmrDhoUCDDcL?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/4U5UXciYphLDZAIgjdz50v?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Visualisations {.storyboard}
==================================================

### Every year looks the same?! {.storyboard}

```{r}
Top2000_scatter <- Top2000lists |>
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")) |>
  ggplot(
    aes(
      x = valence,
      y = danceability,
      colour = mode,
      text = track.name)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~category) +
   scale_x_continuous(
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  theme_classic() +
  labs(
    x = "Valence",
    y = "Danceability",
    colour = "Mode",
  )

ggplotly(Top2000_scatter)
```

***
In this scatter plot you can see the relation between valence, danceability and mode in the TOP2000.

**The features**

The feature 'mode' is quite straight forward: does the song sound more major or minor? Valence and danceability, however, are terms that might need more explanation. Valence tells us something about how happy or sad a song sounds. This means that tracks with a high valence (closer to 1) sound happier or more euphoric and tracks with a low valence (closer to 0) sound sadder, angrier or more depressed. Danceability tells us how suitable a track is for dancing. Again, a value closer to 1 means that you can show your best dance moves while a value closer to 0 means that you are probably standing still.
Unfortunately, Spotify is very vague about how exactly these features are measured. According to their [website for developers](https://developer.spotify.com/documentation/web-api/reference/get-audio-features) danceability is based on elements like tempo, rhythm stability, beat strength and overall regularity. How valence is estimated, is even more unknown.

**The plot: 4 years of TOP2000 in dots**

The general trend in the four years seems very comparable, the dots show a slight diagonal line. Overall, you can probably say that the lower the valence, the less danceable the song and the higher the valence the more danceable the song. There are a few songs that deviate from the diagonal, for example Funkytown by Lipps Inc (in the 1999 plot) and The Next Episode by Dr. Dre and Snoop Dogg (in the 2019 and 2022 plot). Both have a higher dancebility than what one might expect from its valence value.

### How pitch makes Bohemian Rhapsody number 1: chromagrams {.storyboard}
```{r}
Bohemian <-
  get_tidy_audio_analysis("4u7EnebtmKWzUH433cf5Qv") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

Bohemian_chromagram <- Bohemian |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Bohemian Rhapsody \n(Queen)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")


FixYou1 <-
  get_tidy_audio_analysis("7LVHVU3tWfcxj5aiPFEW4Q") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

FixYou1_chromagram <- FixYou1 |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Fix You \n(Coldplay)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")


Brel <-
  get_tidy_audio_analysis("6IRA4KOVbtiGiTdYoEThJN") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

Brel_chromagram <- Brel |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Ne Me Quitte Pas \n(Jacques Brel)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")


Ramses <-
  get_tidy_audio_analysis("4WCySsw36GzONhLAaBtn2g") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

Ramses_chromagram <- Ramses |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Zing - Vecht - Huil - Bid - Lach - \nWerk en Bewonder (Ramses Shaffy)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")

plot_grid(Bohemian_chromagram, Brel_chromagram, FixYou1_chromagram, Ramses_chromagram, axis = "l", ncol = 2, nrow = 2)
```

***
**What is a chromagram?**

A chromagram shows chroma, or "pitch class profiles" over time. A high magnitude (yellow/orange) means that there is a lot of that pitch class present at a certain time. On the contrary, a low magnitude (black/dark purple) means that a pitch class is not detectable at that certain time.

**The number 1: Bohemian Rhapsody**

Let's first take a look at Bohemian Rhapsody by Queen. This is definitely an interesting song in the TOP2000 because of its position in the list. From the first year onwards it has been on number 1 for almost all years. In 2005, 2010, 2014, 2015 and 2020 the song was beaten by either Avond, Hotel California, Imagine or Roller Coaster, however Bohemian Rhapsody still secured a runner up position in these years.

What makes the song so great? If we look at pitch class in the form of the chromagram we can perhaps see why. The song is in three different keys. It starts in the key of Bb in the verse, which becomes very clear by the yellow/orange stripes in the chromagram. Another important moment in the song is the so-called 'opera'-part. This happens around 180 seconds and is visible in the chromagram if you look at the orange area in the key of A. The orange area in A can be explained because this part is starting in A-major and the part modulates back and forth to this key. The song ends in the key of Eb, hence the yellow/orange area around 330s. In general, you could say this song is all over the place pitch-wise because it is changing key often.

**The rising star of the last decade: Fix You**

Queen is not the only band in the TOP2000 that has had a big impact on the list. Coldplay has turned out to also be a favourite over the past few years. Their song Fix You ended up at the 5th place in the edition of 2022.
The chromagram separately shows the chords that are being played at the start. The song begins with an organ that plays Eb Gm Cm7 Gb, as is also shown in the chromagram. From around 150 seconds these individually played chords fade away and make way for other patterns with a high magnitude at Eb, the key of the song. These changing patterns keep the song interesting.

**The French chanson: Ne Me Quitte Pas**

An entirely different genre in the TOP2000 are the French chansons. The previous host of the yearly TV show [TOP2000 à Go-GO](https://nl.wikipedia.org/wiki/Top_2000_%C3%A0_Go-Go), Matthijs van Nieuwkerk is a big fan and has often promoted the genre.
The chromagram for Ne Me Quitte Pas is interesting because there is more happening compared to Fix You but not as much as in Bohemian Rhapsody. I believe this is mainly due to the piano since it doesn't play clear chords in the song. Instead the piano melody is unpredictable and walks through the songs taking new routes every time while circling around the Ab minor that the song is in.

**The dead still singing: Ramses Shaffy**

In 2009 the Dutch chanson singer Ramses Shaffy passed away on the 1st of December. His passing had a huge influence on 2009's edition of the TOP2000 because a lot of his songs ended up a lot higher than they were in the previous years. What about the pitch of his music?
Zing Vecht Huil Bid Lach Werk en Bewonder shows a high magnitude for both the pitch A and D. This can be explained by the key of the song, which is D major. A is the dominant of the tonic D and therefore the second most important tone in this piece.

**Positions in TOP2000**

[Bohemian Rhapsody](https://open.spotify.com/track/4u7EnebtmKWzUH433cf5Qv?si=3de371f1a98e43a4): 1999: no. 1, 2009: no. 1, 2019: no. 1, 2022: no. 1

[Ne Me Quitte Pas](https://open.spotify.com/track/6IRA4KOVbtiGiTdYoEThJN?si=767af0c0a0b14ce4): 1999: no. 66, 2009: no. 94, 2019: no. 415, 2022: no. 244

[Fix You](https://open.spotify.com/track/7LVHVU3tWfcxj5aiPFEW4Q?si=e5956007578143f6): 1999: -, 2009: no. 1494, 2019: no. 8, 2022: no. 5

[Zing Vecht Huil Bid Lach Werk en Bewonder](https://open.spotify.com/track/4WCySsw36GzONhLAaBtn2g?si=e9f401df5af54e4e): 1999: no. 297, 2009: no. 7, 2019: no. 167, 2022: no. 319

### Cepstrograms: Who Wants to Live Forever might be the saddest song in the TOP2000 {.storyboard}
```{r}
Goldband <-
  get_tidy_audio_analysis("2LcmbuYX7tyR4DWy3b273L") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

Goldband_cepstrogram <- Goldband |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 87, colour = "white") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Noodgeval \n(Goldband)") +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic()


Summertime <-
  get_tidy_audio_analysis("4DBZvNW9wB1vHzzRcFbDZF") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

Summertime_cepstrogram <- Summertime |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Summertime \n(Billie Holiday)") +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic()


Nirvana <-
  get_tidy_audio_analysis("11LmqTE2naFULdEP94AUBa") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

Nirvana_cepstrogram <- Nirvana |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 46, colour = "white") +
  geom_vline(xintercept = 87, colour = "white") +
  geom_vline(xintercept = 123, colour = "white") +
  geom_vline(xintercept = 163, colour = "white") +
  geom_vline(xintercept = 218, colour = "white") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Heart-Shaped Box \n(Nirvana)") +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic()


DoeMaar <-
  get_tidy_audio_analysis("46LNQvIkDX7hs0M466DD6h") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

DoeMaar_cepstrogram <- DoeMaar |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 115, colour = "white") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Belle Hélène \n(Doe Maar)") +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic()


plot_grid(Goldband_cepstrogram, Summertime_cepstrogram, Nirvana_cepstrogram, DoeMaar_cepstrogram, ncol = 2, nrow = 2)
```

***
**What is a cepstrogram?**

A cepstrogram is a diagram that is based on timbre. Timbre is sometimes referred to as sound color, texture or quality. The cepstrogram shows the magnitude of all timbre vectors over time, where yellow/orange means that there is a high magnitude for the timbre vector and black/purple that there is a low magnitude. These timbre vectors are certain qualities, c01 for example represents the average loudness and c02 the brightness. These vectors get very complex and abstract and for most of them it is very hard to grasp what they actually stand for.

**Highest new entrant: Noodgeval**

Noodgeval by Goldband was the highest new entrant in the 2022 edition. The white line indicates the change from the chorus to the second verse. Here you can see a drop in magnitude for c01 and an increase for c04. The drop can be understood by listening to the synths and the different voices. Both don't continue into the second verse, it is only the beat and one of the guys singing here, which makes it sound more intimate. c04 stands for the attack of a sound. Right before the white line, when the second verse kicks in, the beat fades away and comes in again with the start of the verse. This explains the increase in magnitude at 87 seconds.

**Perhaps the oldest song in the TOP2000: Summertime**

From one of the newest songs in the TOP2000 we go to one of the oldest ones in the TOP2000. Summertime is a song written by George Gershwin. Billie Holiday is the first one to record the song in 1935. That makes this song one of the oldest ever to appear in the TOP2000. Can timbre show the age of the song?
I would argue yes, based on these four songs at least. If you look at these four cepstrograms you can notice something remarkable for Summertime. It is the only song that has a constant high magnitude for c03. This timbre vector stands for the flatness of the sound. If this quality of flatness is typical for more older songs, is something that would need to be properly researched.

**A grunge classic: Heart-Shaped Box**

Another decade, another type of music: Nirvana is grunge and grunge is Nirvana. Interestingly, their songs only ended up in the TOP2000 in the 10s, about 20 years after they had been active as a band. The cepstrogram for Nirvana's Heart-Shaped Box is fascinating because it clearly shows different parts of the song in the c01 and c02 vector. The white lines indicate where different parts start. The parts with a high magnitude for loudness, c01, are the choruses and the remaining parts the verses. This cepstrogram shows that timbre can tells us more about the structure of a song (more about this in the next tab!).

**One of the happiest songs in the 2022 edition: Belle Hélène**

The 80s are the last decade I want to represent. Doe Maar was active from 1978-1984 and released their song Belle Hélène right after they split up. Sadly, Henny Vrienten, the lead singer and bass player of Doe Maar passed away in 2022. This led to their songs gaining a lot of places in the most recent edition. If we look at the values for valence in 2022, Belle Hélène is in the top 5 happiest songs of the 2022 edition. Is this also visible if we look at the cepstrogram? The magnitudes are relatively constant throughout the song, with a peak around 110 seconds (light yellow). The white line shows the moment when the magnitude for c03 decreases and the magnitude for c04 increases in 3 pulses. These 3 pulses are possibly the singer because the other sounds in the song are constant at this moment. He is singing 3 sentences: 1. Zoals je naast me ligt te slapen. 2. Zo heb ik jou nog niet gezien. 3. Je lijkt ineens geen kind meer.

**Positions in TOP2000**

[Noodgeval](https://open.spotify.com/track/2LcmbuYX7tyR4DWy3b273L?si=43377d5030724a6e): 1999:-, 2009: -, 2019: -, 2022: no. 55

[Summertime](https://open.spotify.com/track/4DBZvNW9wB1vHzzRcFbDZF?si=d2910d8b561f45ca): 1999: no. 562, 2009: no. 1293, 2019: -, 2022: -

[Heart-Shaped Box](https://open.spotify.com/track/11LmqTE2naFULdEP94AUBa?si=0ae9e02314974195): 1999: -, 2009: -, 2019: no. 1019, 2022: no. 797

[Belle Hélène](https://open.spotify.com/track/46LNQvIkDX7hs0M466DD6h?si=d9e59785d8b841f5): 1999: -, 2009: no. 1165, 2019: no. 928, 2022: no. 516


### How is one of the saddest songs in the TOP2000 structured: Self-similarity Matrices {.storyboard}
```{r}
Queen9 <-
  get_tidy_audio_analysis("3SGP8It5WDnCONyApJKRTJ") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  Queen9 |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  Queen9 |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Who Wants to Live Forever (Queen)")


ABBA9 <-
  get_tidy_audio_analysis("0GjEhVFGZW8afUYGChu3Rr") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  ABBA9 |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  ABBA9 |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Dancing Queen (ABBA)")

plot_grid(Queen9, ABBA9, ncol = 1, nrow = 2, align = "h")
```

***
**Self-similarity matrices**

A self-similarity matrix can explain the structure of the song. These matrices can be either based on chroma (pitch class) or timbre. In simple terms: a coloured square over the diagonal indicates a different part of the song. 

**Saddest song in the TOP2000: Who Wants to Live Forever**

Queen's Bohemian Rhapsody might be the number 1 but one of the saddest and least danceable songs in the TOP2000 is Queen's Who Wants to Live Forever (you can try to find it in the scatterplot on the first tab!).
In both matrices for this song, there are some clear distinctions visible between different parts of the song. The chroma matrix tells us that the song can be divided into about 3 parts, but the timbre matrix separates a few more, smaller changes. The biggest change happens around 120 seconds when the second verse starts. This verse is different from the first verse because it has a loud drum kicking in. It is remarkable that there is not much similarity at all between parts, according to the matrices. This perhaps explains why Spotify's data says it is not a very danceable song.

**Everyone's favourite Eurovision band: ABBA**

This is a self-similarity matrix based on ABBA's song Dancing Queen. A much happier song compared to Who Wants to Live Forever. Both the chroma and timbre matrix show clearly that Dancing Queen consists of several parts, also with similar structures (which wasn't the case for Queen's sad song). Dancing Queen starts with an intro that evolves into a part of the chorus. After this, from 43 seconds, the first verse starts. In the timbre matrix this is the second purple square that follows the diagonal. The third purple box that starts at around 85 seconds indicates the start of the chorus. The chorus is followed by a shorter second verse, another chorus and an outro. The chroma matrix tells us that the song can be cut into even smaller sections, the chorus can for example be divided into two parts.

**Positions in TOP2000**

[Who Wants To Live Forever](https://open.spotify.com/track/3SGP8It5WDnCONyApJKRTJ?si=dba1813eb9644cd7): 1999: no. 30, 2009: no. 77, 2019: no. 74, 2022: no. 101

[Dancing Queen](https://open.spotify.com/track/0GjEhVFGZW8afUYGChu3Rr?si=8e4e72e8444f442f): 1999: no. 16, 2009: no. 70, 2019: no. 68, 2022: no. 44

### Key-changes are exciting! Keygrams {.storyboard}
```{r}
Waterboys <-
  get_tidy_audio_analysis("11zWfCQaGkXJ9uIXROr4pa") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Waterboys_keygram <- Waterboys |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "The Whole of the Moon \n(The Waterboys)")


Backstreet <-
  get_tidy_audio_analysis("47BBI51FKFwOMlIiX6m8ya") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Backstreet_keygram <- Backstreet |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "I Want It That Way \n(Backstreet Boys)")


Beatles <-
  get_tidy_audio_analysis("5dfvhl9mJqgMVLNm3LAMnG") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Beatles_keygram <- Beatles |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Penny Lane \n(The Beatles)")

plot_grid(Waterboys_keygram, Backstreet_keygram, Beatles_keygram, ncol = 2, nrow = 2)
```

***
**What is a keygram?**

A keygram shows the key for a section over time. For this 'gram', the darkest area (black/dark purple) tells us the key the section is in. The y-axis show all the keys, ordered by the circle of fifths, which means that the keys next to each other on the y-axis are most similar because they share most notes. 

**My dad's favourite: The Whole of the Moon**

One of my dad's favourite songs in the TOP2000 turns out to be a great example to show how keygrams work. The Whole of the Moon by the Waterboys is a family classic and every year we hope it gains a few places. Since 2005 the song has had a stable position, somewhere between no. 320 to no. 410. Maybe I'm biased, but the keygram makes the song look very boring. The song starts in C major, the song ends in C major and in between nothing really happens either. At some points it is unclear whether the keygram shows C major, F major or even C minor, but by listening to the music it becomes pretty clear that really nothing changes. Either other features of the song make it interesting, or my dad likes simplicity. 

**I Want It That Way**

The Backstreet Boys spice it up a little bit by adding a modulation to their song I Want It That Way. First of all, it is not very clear if the song is in A major or F# minor, the patches are equally as purple. The answer is that the song probably is written in A major, but that the song has a lot of quality for F# minor too. A major makes more sense when we look at the modulation that is happening around 147 seconds. The second part of the song is in B major, which is a whole step up from A major. A modulation from F#m to B would also be possible but it is not as common, hence why I think it is more likely that the song starts in A major.

**Penny Lane**

There is no way that I can't mention the Beatles in this project. In a lot of editions the band had most songs in the list. In 2008 they reached an all time high with 55 songs in the TOP2000. One of these songs is Penny Lane.
Based on the key, the song is more complex than the other two mentioned on this tab. According to the keygram, a large portion of the song is in Gb major(/F# major). However, this turned out to be a mistake, instead the song's main key is B major. The dominant tone for this key is F#, which is probably why the keygram shows the key of F# major. The verses are in B major, but the song modulates to A major going into the choruses. Additionally, the last chorus is repeated using the same modulation as in I want it that way, a whole step up from A major. The song is now back and ends in the 'original key' B major. This alternating of keys contributes to the contrasting verse and chorus form that the song uses.

**Positions in TOP2000**

[The Whole of the Moon](https://open.spotify.com/track/11zWfCQaGkXJ9uIXROr4pa?si=0d5f44d5aaad4727): 1999: -, 2009: no. 407, 2019: no. 366, 2022: no. 399

[I Want It That Way](https://open.spotify.com/track/47BBI51FKFwOMlIiX6m8ya?si=341df457e9f94861): 1999: -, 2009: no. 1569, 2019: no. 1014, 2022: no. 910

[Penny Lane](https://open.spotify.com/track/1sjmKmR4u9xDeJHjDCn2bZ?si=a4924e3ad4b0479b): 1999: no. 266, 2009: no. 324, 2019: no. 377, 2022: no. 563


### Tempograms: Rainbow in the Sky and Killing in the Name {.storyboard}
```{r}
Rainbow <- get_tidy_audio_analysis("2MlqP1HzhitHfFXPXKumdB")

Rainbow_tempogram <- Rainbow |>
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = 'none') +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Rainbow In The Sky \n(Paul Elstak)") +
  theme_classic()

Killing <- get_tidy_audio_analysis("59WN2psjkt1tyaxjspN8fp")

Killing_tempogram <- Killing |>
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = 'none') +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Killing In The Name \n(Rage Against The Machine)") +
  theme_classic()

plot_grid(Rainbow_tempogram, Killing_tempogram, ncol = 1)
```

***
**What is a tempogram?**

A tempogram shows the BPM of a song over time. In this case the yellow lines show the BPM at a certain point in the song. Sometimes there is more than one yellow line visible, these 'extra' lines are tempo octaves.

**The tempogram of Rainbow in the Sky**

Rainbow in the Sky was released in 1995 but only entered the TOP2000 in 2015 at no. 765. Since, the song has been gaining a few places each year. Last edition, in 2022, the song ended up at the highest position yet, no. 366.

This is a tempogram of Rainbow in the Sky by DJ Paul Elstak. The tempogram shows a straight line throughout the entire song around 360 BPM. At around 10 seconds and 75 seconds there are other yellow dots visible for 180 BPM, these are the tempo octaves. Rainbow in the Sky is an electronic track in the genre of happy hardcore. This explains the straight line in the tempogram, the electronically created beats happen in a very steady pace.

**The tempogram of Killing in the Name**

Just like Rainbow in the Sky, Killing in the Name was released (in 1992) many years before its introduction to the TOP2000 in 2011. Although the song entered at a relatively low position (no. 1454), the song has kept a steady position in the years following: ranging between no. 94 and no. 48. 

The tempogram of Killing in the Name by the band Rage Against the Machine looks very different compared to Rainbow in the Sky's tempogram. In this tempogram there is no straight yellow line. This can mean a few things. Firstly, Killing in the Name isn't an electronic track like Rainbow in the Sky. This means that the drummer needs to keep the exact same pace for some time, which can be challenging. That makes the tempo in Killing in the Name automatically more dynamic and the yellow lines not as straight. A second reason for the bumpy lines could be the noise in the song. Everything in the song comes across as loud, the singing (or one could say almost screaming) and the lead guitar that has several solos for example. These parts don't have a very clear on beat tempo which might interfere with the tempo of the drums. The final reason for why there isn't a straight line, can be the tempo changes. These changes are quite obvious when you listen to the song. A clear example of one of these changes is at 2 min. 25 (145 seconds). The song switches here from the chorus to the second verse. The chorus has strong vocals and a heavy guitar with a slightly faster beat than the verse which has the characteristic guitar riff with softer vocals.

**Positions in TOP2000**

[Rainbow in the Sky](https://open.spotify.com/track/2MlqP1HzhitHfFXPXKumdB?si=e2bdad09cfb343b4): 1999: -, 2009: -, 2019: no. 386, 2022: no. 366

[Killing In The Name](https://open.spotify.com/track/59WN2psjkt1tyaxjspN8fp?si=00be500cee6e4ae7): 1999: -, 2009: -, 2019: no. 60, 2022: no. 48

### Timbre in the Top 2000 {.storyboard}
```{r}
Top1999timbre1 <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0qSHbyaiZbhacDdIegMoBR"
  ) |>
  slice(1:250) |>
  add_audio_analysis()
Top2009timbre1 <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "6BJbzcSvOunQpVCJuBLxEW"
  ) |>
  slice(1:250) |>
  add_audio_analysis()
Top2019timbre1 <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "1MaaUHHVuXbmrDhoUCDDcL"
  ) |>
  slice(1:250) |>
  add_audio_analysis()
Top2022timbre1 <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "4U5UXciYphLDZAIgjdz50v"
  ) |>
  slice(1:250) |>
  add_audio_analysis()
Top2000timbre1 <-
  bind_rows(
   Top1999timbre1 |> mutate(year = "1999"),
   Top2009timbre1 |> mutate(year = "2009"),
   Top2019timbre1 |> mutate(year = "2019"),
   Top2022timbre1 |> mutate(year = "2022")
  )
```

```{r, fig.width=10, fig.height=4}
Top2000timbre1 |>
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) |>
  select(year, timbre) |>
  compmus_gather_timbre() |>
  ggplot(aes(x = basis, y = value, fill = year)) +
  geom_violin() +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Year")
```

***
This plot shows the timbre values from 4 years of the TOP 2000. Only the first 250 songs of the playlists are used for this plot. A few timbre coefficients show few differences between the four years. The biggest difference is visible in c02, this is the coefficient for brightness. The year of 1999 stand out because its violin is longer than the other violins. Overall there aren't too many differences which suggests that the first 250 songs in these playlists "sound" relatively the same. It would be interesting to research whether the results would be the same if all 2000 songs were included and not just the top 250.

### Loudness, tempo and duration {.storyboard}
```{r}
Top2000timbreplotly <- Top2000timbre1 |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = loudness,
      text = track.name
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  facet_wrap(~year) +
  theme_light() +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    size = "Duration (min)",
    colour = "Volume (dBFS)"
  )

ggplotly(Top2000timbreplotly)
```

***
This scatterplot visualises volume, tempo and duration of the first 250 tracks from each TOP2000 year in the corpus.

**The features**

What do volume, tempo and duration mean? Duration stands for the length of the song, in the plot this is reflected by the size of the dots: the bigger the dot, the longer the song. Furthermore, the duration is given in minutes. Tempo is shown in two ways, the mean tempo in Beats Per Minute (BPM) on the x-axis and the standard deviation of the tempo on the y-axis. Volume is what Spotify calls loudness. In this scatterplot volume is represented by colour where red means loud and green means soft.

**The plot**

In the previous tab we saw that there aren't that many differences in timbre between the 4 years. I would argue that that is the case for this plot. The distribution of the dots is relatively comparable for the 4 years. In all four years there are 2 big clusters of dots, the first one between 1 and 2.25 SD Tempo and 100-125 BPM. The second cluster is located between 0 and 1 SD Tempo and 125-150 BPM. Moreover, the duration of the songs (size of the dots) and the amount of green and red also seems similar for all 4 years.

### Dendrogram 1999 {.storyboard}
```{r}
Top1999timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0qSHbyaiZbhacDdIegMoBR"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2009timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "6BJbzcSvOunQpVCJuBLxEW"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2019timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "1MaaUHHVuXbmrDhoUCDDcL"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2022timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "4U5UXciYphLDZAIgjdz50v"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2000timbre <-
  bind_rows(
   Top1999timbre |> mutate(year = "1999"),
   Top2009timbre |> mutate(year = "2009"),
   Top2019timbre |> mutate(year = "2019"),
   Top2022timbre |> mutate(year = "2022")
  )
```

```{r, fig.width=12, fig.height=5}
Dendro1999 <-
  get_playlist_audio_features("1999", "6VEGxOyJCx6WYTXJIBy0tb") |> 
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro1999_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro1999
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro1999 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro1999_dist <- dist(Dendro1999_juice, method = "euclidean")

Dendro1999_dist |> 
  hclust(method = "average") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()
```

***
**What is a dendrogram?**

A dendrogram is a visualisation of different groups within a dataset or corpus. It shows how similar or dissimilar, in this case, songs are based on chosen features. The distance between the branches and the height of the branches represent whether songs are closely related or not. A shorter distance or height means that songs or groups of songs are more similar to each other.

**Tonight I'm gonna party like it's 1999**

This dendrogram contains the first 100 songs of the TOP2000 from 1999 and is only based on the 12 timbre coefficients. There are a few noticeable groups that I want to highlight. 

Dreadlock Holiday (10cc) and Roxanne (The Police) are for example similar according to the dendrogram. This makes a lot of sense because both songs are influenced by reggae music. The rhythms as well as the guitar riff in both songs share the same reggae sounding quality.

Another group consists of My Heart Will Go On (Celine Dion), Bridge Over Troubled Water (Simon & Garfunkel), Who Wants To Live Forever (Queen). In the first tab, with the scatterplot about the relation between valence, danceability and mode, you can actually see that these three songs are quite close together, all have a low danceability and low valence value. If the dendrogram was based on valence and danceability then My Heart Will Go On and Who Wants To Live Forever would have been the closest together from these 3 songs. Instead, with the dendrogram based on timbre, Who Wants To Live Forever and Bridge Over Troubled Water share most similarities.

Lastly, it is also interesting that sometimes two songs by the same artists are considered most similar out of these 100 songs. There is for example a duo with Let It Be and Strawberry Fields Forever by The Beatles and another duo is Dancing Queen and The Winner Takes It All by ABBA. A reason for this can be the production of these songs, the voices of these artists and/or the use of instruments.


### Dendrogram 2009
```{r, fig.width=12, fig.height=5}
Dendro2009 <-
  get_playlist_audio_features("2009", "0qoaHjMRoMN7v9A56R5yYB") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro2009_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro2009
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro2009 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro2009_dist <- dist(Dendro2009_juice, method = "euclidean")

Dendro2009_dist |> 
  hclust(method = "average") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()

```

***
**What is a dendrogram?**

A dendrogram is a visualisation of different groups within a dataset or corpus. It shows how similar or dissimilar, in this case, songs are based on chosen features. The distance between the branches and the height of the branches represent whether songs are closely related or not. A shorter distance or height means that songs or groups of songs are more similar to each other.

**Tonight I'm gonna party like it's 2009**

This dendrogram contains the first 100 songs of the TOP2000 from 2009 and is only based on the 12 timbre coefficients. These figures don't allow double track names at the end of the branches, which is why you won't be able to find One by Metallica in the dendrogram. The "One" in the dendrogram is the song by U2. In this dendrogram are also a few groups that I want to point out.

Firstly, songs that are close together in the dendrogram with the data from 1999 are mostly also close together in this dendrogram. Who Wants To Live Forever (Queen) and Bridge Over Troubled Water (Simon & Garfunkel) are for example still a duo and Sunday Bloody Sunday (U2) got even closer to Dancing Queen (ABBA) because The Winner Takes It All (ABBA) is not part of the top 100 in 2009.

Again, songs with the same genre find each other. Smells Like Teen Spirit (Nirvana) and Alive (Pearl Jam) are similar according to this dendrogram. Both songs are released in 1991 and both songs are grunge/alternative rock with heavy guitars and the raw voices of Kurt Cobain and Eddie Vedder. 

The most interesting thing from this dendrogram is probably the two clusters of Dutch songs. There is one cluster with the songs Dochters (Marco Borsato), Avond (Boudewijn de Groot), De Vondeling van Ameland (Boudewijn de Groot) and one cluster with the songs Over de Muur (Klein Orkest), Zing Vecht Huil Bid Lach Werk en Bewonder (Ramses Shaffy), Het Dorp (Wim Sonneveld). Furthermore, these two clusters are close together as well. This could mean that there's a specific Dutch sound in certain songs.


### Dendrogram 2019
```{r, fig.width=12, fig.height=5}
Dendro2019 <-
  get_playlist_audio_features("2019", "3qlSwTObXFlCAPg6HMOT7h") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro2019_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro2019
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro2019 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro2019_dist <- dist(Dendro2019_juice, method = "euclidean")

Dendro2019_dist |> 
  hclust(method = "average") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()
```

***
**What is a dendrogram?**

A dendrogram is a visualisation of different groups within a dataset or corpus. It shows how similar or dissimilar, in this case, songs are based on chosen features. The distance between the branches and the height of the branches represent whether songs are closely related or not. A shorter distance or height means that songs or groups of songs are more similar to each other.

**Tonight I'm gonna party like it's 2019**

This dendrogram contains the first 100 songs of the TOP2000 from 2019 and is only based on the 12 timbre coefficients. These figures don't allow double track names at the end of the branches, which is why you won't be able to find Hallelujah by Jeff Buckley, One by Metallica and One by Mary J Blige and U2 in the dendrogram. The "Hallelujah" in the dendrogram is Leonard Cohen's version and the "One" in the dendrogram is the song by U2. There are a few noticeable groups that I want to highlight. 

Sometimes the dendrogram can be very suprising and put songs together that you would have never expected to be so closely related of all the songs in the corpus. An example is A Forest (The Cure) and Mag Ik Dan Bij Jou (Claudia De Breij). The branches are high but out of all top 100 songs these are apparently the most similar to each other. I spent a good amount of time trying to understand how this is possible because when I first saw this I was shocked. After giving it some thought I think it perhaps has something to do with the flatness of the songs. Both are like a stream of water that keeps flowing while nothing much changes in the sound.

Another noticeable song is Sound of Silence. In the top 100 of 2019 the song appears twice, the original by Simon & Garfunkel and the cover by Disturbed. Both songs sound completely different and therefore it was expected that both songs would end up far away from each other but I think it is still worth mentioning.

### Dendrogram 2022
```{r, fig.width=12, fig.height=5}
Dendro2022 <-
  get_playlist_audio_features("2022", "3mC8WmcqnXTtM0A4hOKyNc") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro2022_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro2022
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro2022 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro2022_dist <- dist(Dendro2022_juice, method = "euclidean")

Dendro2022_dist |> 
  hclust(method = "average") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()
```


***
**What is a dendrogram?**

A dendrogram is a visualisation of different groups within a dataset or corpus. It shows how similar or dissimilar, in this case, songs are based on chosen features. The distance between the branches and the height of the branches represent whether songs are closely related or not. A shorter distance or height means that songs or groups of songs are more similar to each other.

**Tonight I'm gonna party like it's 2022**

This dendrogram contains the first 100 songs of the TOP2000 from 2022 and is only based on the 12 timbre coefficients. These figures don't allow double track names at the end of the branches, which is why you won't be able to find The Sound of Silence by Disturbed, One by Metallica and One by Mary J Blige and U2 in the dendrogram. The "Sound of Silence" in the dendrogram is Simon and Garfunkel's version and the "One" in the dendrogram is the song by U2. There are a few noticeable groups that I want to highlight. 

In this dendrogram the genre hardrock is clearly grouped together. Deutschland (Rammstein), Phantom of the Opera (Floor Jansen, Henk Poort) and Uprising (Muse) are clustered. Somewhere else Du Hast (Rammstein) and Enter Sandman (Metallica) also form a duo cluster. Surprisingly, these two clusters are not directly next to each other, which I would have expected as all of these songs are roughly the same genre. For the same reason I would have expected Master of Puppets (Metallica) closer to either of these clusters, but instead this song is apparently most similar to Under the Bridge (Red Hot Chili Peppers)

Lastly, it is also interesting to see what the most recent track is similar to. Noodgeval (Goldband), the highest new entrant, is next to Lose Yourself (Eminem) in the dendrogram. 
I don't think this is very shocking because Noodgeval also has some of the hiphop/rap features that Lose Yourself has. Throughout Noodgeval there isn't much singing for example, it's not rapping either but it's definitely closer to this. 

Conclusion
=================================================

Column {data-width=500}
---------------------------------------------------

### Results

For this project I wanted to find out whether the sound of the TOP2000 has changed over the past 23 years. I have analysed individual songs, as well as the lists of four years as a whole to try come to a conclusion. I have tried to analyse as many different songs as possible, including outliers, several genres and eras.

**Chromagrams**

The chromagrams showed that there are different levels of complexity when it comes to use of chroma. However, the level of complexity doesn't necessarily give the song a better position in the TOP2000. From the chromagrams we are able to distinguish different parts of songs (Fix You), but we are also able to do this if we use cepstrograms (Heart-Shaped Box). 

**Cepstrograms**

For the cepstrograms I used songs from different decades. Summertime stood out by showing a high magnitude for c03 which makes me believe that it might be possible

**

Column {data-width=250}
---------------------------------------------------

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/0qSHbyaiZbhacDdIegMoBR?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6BJbzcSvOunQpVCJuBLxEW?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Column {data-width=250}
---------------------------------------------------

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/1MaaUHHVuXbmrDhoUCDDcL?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/4U5UXciYphLDZAIgjdz50v?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
