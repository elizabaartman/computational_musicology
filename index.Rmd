---
title: "Portfolio Computational Musicology"
author: "Eliza"
date: "spring 2023"
output: 
  flexdashboard::flex_dashboard:
    self_contained: false
    theme: simplex
    vertical_layout: fill
    horizontal_layout: fill
---

```{r}
library(tidyverse)
library(spotifyr)
library(compmus)
library(plotly)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(cowplot)
```

```{r}
Top1999 <- get_playlist_audio_features("", "0qSHbyaiZbhacDdIegMoBR")
Top2009 <- get_playlist_audio_features("", "6BJbzcSvOunQpVCJuBLxEW")
Top2019 <- get_playlist_audio_features("", "1MaaUHHVuXbmrDhoUCDDcL")
Top2022 <- get_playlist_audio_features("", "4U5UXciYphLDZAIgjdz50v")

Top2000lists <-
  bind_rows(
    Top1999 |> mutate(category = "1999"),
    Top2009 |> mutate(category = "2009"),
    Top2019 |> mutate(category = "2019"),
    Top2022 |> mutate(category = "2022")
  )
```

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

What is the TOP2000?
===================================================

Column {data-width=500}
---------------------------------------------------

### What is the TOP2000?

**"The list of lists"**

The TOP2000 is a Dutch radio programme by radio station NPO radio 2. From Christmas Day until midnight of New Year's Eve, a list of 2000 songs that are considered the "most popular songs of all time", is broadcasted. The list, constructed by votes from the audience, was first on air in 1999 to celebrate the new millennium. Due to the success of the show, the radio station decided to make it an annual programme. In the following years, the TOP2000 grew out to become a yearly tradition for many households.

The list of 2000 songs has changed over the years with new songs entering the TOP2000 and other songs not making it to the final cut. New generations of kids grew up listening to the show with their parents and are voting on their favourite songs now too. More recent hits are making it to the list every year (see statistics [here](https://www.nporadio2.nl/top2000/statistieken)) and most likely making the list conform to its time. What exactly are the differences between the list throughout the years and has the sound of the TOP2000 changed over the past 23 years?


**The TOP2000 of 1999, 2009, 2019 and 2022**

The corpus consists of four playlists: the TOP2000 list from 1999, 2009, 2019 and 2022. The 2000 songs that should be included can be found on the NPO radio 2 [website](https://www.nporadio2.nl/top2000). I am using two already existing playlists on Spotify that I have checked on accuracy, the other two playlists I have created myself. Even though the playlists are carefully constructed, there are a few songs missing. This is not the fault of the creator, Spotify simply doesn't have the songs in its library. This results in the list from 1999 containing a total of 1976 songs, 2009 has 1982 songs, the list from 2019 contains 1993 songs and 2022 has the most with 1999 songs. The amount of songs missing is limited and should therefore not cause too many problems for the data analysis.

An example of a song that is remarkable in the TOP2000 is Danny Vera's Roller Coaster. The song entered the list in 2019, immediately making it to the 4th place. Ever since it has been in the top 3 which has not happened with other songs before. If we look at the TOP2000 of 1999 it is interesting to see that Avond by Boudewijn de Groot was only placed at 428. The song has grown in popularity because it now has positioned itself on the 8th place. I expect that newly released songs like Roller Coaster and songs gaining a lot more popularity over time like for example Avond have changed the general sound of the TOP2000 over its years. 

Column {data-width=250}
---------------------------------------------------

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/0qSHbyaiZbhacDdIegMoBR?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6BJbzcSvOunQpVCJuBLxEW?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Column {data-width=250}
---------------------------------------------------

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/1MaaUHHVuXbmrDhoUCDDcL?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### {data-height=500}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/4U5UXciYphLDZAIgjdz50v?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Visualisations {.storyboard}
==================================================

### Every year looks the same?! {.storyboard}

```{r}
Top2000_scatter <- Top2000lists |> 
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")) |>
  ggplot(
    aes(
      x = valence,
      y = danceability,
      colour = mode,
      text = track.name)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~category) +
   scale_x_continuous(
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),  
    minor_breaks = NULL    
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  theme_classic() +
  labs(
    x = "Valence",
    y = "Danceability",
    colour = "Mode",
  )

ggplotly(Top2000_scatter)
```

***
In this scatter plot you can see the relation between valence, danceability and mode in the TOP2000.

**The features**

The feature 'mode' is quite straight forward: does the song sound more major or minor? Valence and danceability, however, are terms that might need more explanation. Valence tells us something about how happy or sad a song sounds. This means that tracks with a high valence (closer to 1) sound happier or more euphoric and tracks with a low valence (closer to 0) sound sadder, angrier or more depressed. Danceability tells us how suitable a track is for dancing. Again, a value closer to 1 means that you can show your best dance moves while a value closer to 0 means that you are probably standing still.
Unfortunately, Spotify is very vague about how exactly these features are measured. According to their [website for developers](https://developer.spotify.com/documentation/web-api/reference/get-audio-features) danceability is based on elements like tempo, rhythm stability, beat strength and overall regularity. How valence is estimated, is even more unknown as nothing, not a single musical element, is mentioned here.

**4 years TOP2000**

The general trend in the four years seems very comparable, the dots show a slight diagonal line. Overall you can probably say that the lower the valence, the less danceable the song and the higher the valence the more danceable the song.

### How pitch makes Bohemian Rhapsody number 1: chromagrams {.storyboard}
```{r}
Bohemian <- 
  get_tidy_audio_analysis("4u7EnebtmKWzUH433cf5Qv") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

Bohemian_chromagram <- Bohemian |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Bohemian Rhapsody \n(Queen)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")


Brel <- 
  get_tidy_audio_analysis("6IRA4KOVbtiGiTdYoEThJN") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

Brel_chromagram <- Brel |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Ne Me Quitte Pas \n(Jacques Brel)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")


FixYou1 <- 
  get_tidy_audio_analysis("7LVHVU3tWfcxj5aiPFEW4Q") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

FixYou1_chromagram <- FixYou1 |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Fix You \n(Coldplay)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")


Ramses <- 
  get_tidy_audio_analysis("4WCySsw36GzONhLAaBtn2g") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

Ramses_chromagram <- Ramses |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Zing - Vecht - Huil - Bid - Lach - \nWerk en Bewonder (Ramses Shaffy)") +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", guide = "none")

plot_grid(Bohemian_chromagram, Brel_chromagram, FixYou1_chromagram, Ramses_chromagram, axis = "l", ncol = 2, nrow = 2)
```

***
**What is a chromagram?**

A chromagram shows chroma, or "pitch class profiles" over time. A high magnitude (light blue) means that there is a lot of that pitch class present at a certain time. On the contrary a low magnitude (dark blue) means that a pitch class is not detectable at that certain time.

**The number 1: Bohemian Rhapsody**

Let's first take a look at Bohemian Rhapsody by Queen. This is definitely an interesting song in the TOP2000 because of its position in the list. From the first year onwards it has been on number 1 for almost all years. In 2005, 2010, 2014, 2015 and 2020 the song was beaten by either Avond, Hotel California, Imagine or Roller Coaster, however Bohemian Rhapsody still secured a runner up position.

What makes the song so great? If we look at pitch class in the form of the chromagram we can perhaps see why. The song is in three different keys. It starts in the key of Bb in the verse, which becomes very clear by the light blue stripes in the chromagram. Another important moment in the song is the so-called 'opera'-part. This happens around 3 minutes, (or 180 seconds) and is visible in the chromagram if you look at the greener area in the key of A. The greener area in A can be explained because this part is starting in A-major and the part modulates back and forth to this key. The song ends in the key of Eb, hence the light blue area around 330s. In general, you could say this song is all over the place pitch-wise because it is changing key often (I have only outlined the big changes, a lot more is happening!).

**The rising star of the last decade: Fix You**

Queen is not the only band in the TOP2000 that has had a big impact on the list. Coldplay has turned out to also be a favourite over the past few years. Their song Fix You ended at the 5th place in the edition of 2022.
The chromagram separately shows the chords that are being played at the start. The song begins with an organ that plays Eb Gm Cm7 Gb, as is also shown in the chromagram. From around 150 seconds these individually played chords fade away and make way for other patterns with a high magnitude at Eb, the key of the song.

**The French chanson: Ne Me Quitte Pas**

The French chansons in the TOP2000 are popular. The previous host of the yearly TV show [TOP2000 à Go-GO](https://nl.wikipedia.org/wiki/Top_2000_%C3%A0_Go-Go), Matthijs van Nieuwkerk is a big fan and has often promoted the genre.
The chromagram for Ne Me Quitte Pas is interesting because there is more happening compared to Fix You but not as much as in Bohemian Rhapsody. I believe this is mainly due to the piano that doesn't play clear chords. Instead the piano melody is unpredictable and walks through the songs taking new routes every time while circling around the Ab minor that the song is in.

**The dead still singing: Ramses Shaffy**

In 2009 the Dutch chanson singer Ramses Shaffy passed away on the 1st of December. His passing had a huge influence on 2009's edition of the TOP2000 because a lot of his songs ended up a lot higher than they were in the previous years. What about the pitch of his music?
Zing Vecht Huil Bid Lach Werk en Bewonder shows a high magnitude for both the pitch A and D. This can be explained by the key of the song, which is D major. A is the dominant of the tonic D and therefore the second most important note in this piece.

**Positions in TOP2000**

[Bohemian Rhapsody](https://open.spotify.com/track/4u7EnebtmKWzUH433cf5Qv?si=3de371f1a98e43a4): 1999: no. 1, 2009: no. 1, 2019: no. 1, 2022: no. 1

[Ne Me Quitte Pas](https://open.spotify.com/track/6IRA4KOVbtiGiTdYoEThJN?si=767af0c0a0b14ce4): 1999: no. 66, 2009: no. 94, 2019: no. 415, 2022: no. 244

[Fix You](https://open.spotify.com/track/7LVHVU3tWfcxj5aiPFEW4Q?si=e5956007578143f6): 1999: -, 2009: no. 1494, 2019: no. 8, 2022: no. 5

[Zing Vecht Huil Bid Lach Werk en Bewonder](https://open.spotify.com/track/4WCySsw36GzONhLAaBtn2g?si=e9f401df5af54e4e): 1999: no. 297, 2009: no. 7, 2019: no. 167, 2022: no. 319

### Cepstrograms: Who Wants to Live Forever might be the saddest song in the TOP2000 {.storyboard}
```{r}
Goldband <-
  get_tidy_audio_analysis("2LcmbuYX7tyR4DWy3b273L") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

Goldband_cepstrogram <- Goldband |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 87, colour = "white") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Noodgeval \n(Goldband)") +
  scale_fill_viridis_c(option = "B", guide = "none") +                             
  theme_classic()


Summertime <-
  get_tidy_audio_analysis("4DBZvNW9wB1vHzzRcFbDZF") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

Summertime_cepstrogram <- Summertime |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Summertime \n(Billie Holiday)") +
  scale_fill_viridis_c(option = "B", guide = "none") +                             
  theme_classic()


Nirvana <-
  get_tidy_audio_analysis("11LmqTE2naFULdEP94AUBa") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

Nirvana_cepstrogram <- Nirvana |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 46, colour = "white") +
  geom_vline(xintercept = 87, colour = "white") +
  geom_vline(xintercept = 123, colour = "white") +
  geom_vline(xintercept = 163, colour = "white") +
  geom_vline(xintercept = 218, colour = "white") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Heart-Shaped Box \n(Nirvana)") +
  scale_fill_viridis_c(option = "B", guide = "none") +                             
  theme_classic()


DoeMaar <-
  get_tidy_audio_analysis("46LNQvIkDX7hs0M466DD6h") |>
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

DoeMaar_cepstrogram <- DoeMaar |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Belle Hélène \n(Doe Maar)") +
  scale_fill_viridis_c(option = "B", guide = "none") +                            
  theme_classic()


plot_grid(Goldband_cepstrogram, Summertime_cepstrogram, Nirvana_cepstrogram, DoeMaar_cepstrogram, ncol = 2, nrow = 2)
```

***
**What is a cepstrogram?**

A cepstrogram is a diagram that is based on timbre. Timbre is sometimes referred to as sound color, texture or quality. The cepstrogram shows the magnitude of all timbre vectors over time. These timbre vectors are certain qualities, c01 represents the average loudness and c02 the brightness. These vectors get very complex and for most of them it is very hard to grasp what they actually stand for.

**Highest new entrant: Noodgeval**

Noodgeval by Goldband was the highest new entrant in the 2022 edition. The red line indicates the change from the chorus to the second verse. Here you can see a drop in magnitude for c01 and an increase for c04. The drop can be explained by listening to the synths and the different voices. Both don't continue into the second verse, it is only the beat and one of the guys singing here which makes it sound more chilled. c04 stands for the attack of a sound. At the red line, right before the second verse kicks in, the beat fades away and comes in again with the start of the verse.

**Perhaps the oldest song in the TOP2000: Summertime**

Summertime is a song written by George Gershwin. Billie Holiday is the first one to record the song in 1935. That makes this song one of the oldest ever to appear in the TOP2000. Can timbre show the age of the song?
I would argue yes, based on these four songs at least. If you look at these four cepstrograms you can notice something remarkable for Summertime. It is the only song that has a constant high magnitude for c03. This timbre vector stands for the flatness of the sound. If this quality of flatness is something typical for more older songs is of course something that would need to be properly researched.

**A grunge classic: Heart-Shaped Box**

Nirvana is grunge and grunge is Nirvana. Their songs only ended up in the TOP2000 in the 10s, about 20 years after they had been active as a band. The cepstrogram for Nirvana's Heart-Shaped Box is interesting because it clearly shows different parts of the song in the c01 and c02 vector. The red lines indicate where different parts start. The parts with a high magnitude for loudness, c01, are the choruses and the remaining parts the verses. 

**One of the happiest songs in the 2022 edition: Belle Hélène**

Sadly, Henny Vrienten, the lead singer and bass player of Doe Maar passed away in 2022. This led to their songs gaining a lot of places in the most recent edition. If we look at the values for valence in 2022, then Belle Hélène is in the top 5 happiest songs of the 2022 edition. Is this also visible if we look at the cepstrogram? The magnitudes are relatively constant throughout the song, with a peak 

**Positions in TOP2000**

[Noodgeval](https://open.spotify.com/track/2LcmbuYX7tyR4DWy3b273L?si=43377d5030724a6e): 1999:-, 2009: -, 2019: -, 2022: no. 55

[Summertime](https://open.spotify.com/track/4DBZvNW9wB1vHzzRcFbDZF?si=d2910d8b561f45ca): 1999: no. 562, 2009: no. 1293, 2019: -, 2022: -

[Heart-Shaped Box](https://open.spotify.com/track/11LmqTE2naFULdEP94AUBa?si=0ae9e02314974195): 1999: -, 2009: -, 2019: no. 1019, 2022: no. 797

[Belle Hélène](https://open.spotify.com/track/46LNQvIkDX7hs0M466DD6h?si=d9e59785d8b841f5): 1999: -, 2009: no. 1165, 2019: no. 928, 2022: no. 516


### How is one of the saddest songs in the TOP2000 structured: Self-similarity Matrices {.storyboard}
```{r}
Queen9 <-
  get_tidy_audio_analysis("3SGP8It5WDnCONyApJKRTJ") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  Queen9 |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  Queen9 |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "", title = "Who Wants to Live Forever (Queen)")


ABBA9 <-
  get_tidy_audio_analysis("0GjEhVFGZW8afUYGChu3Rr") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  ABBA9 |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  ABBA9 |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "", title = "Dancing Queen (ABBA)")

plot_grid(Queen9, ABBA9, ncol = 1, nrow = 2, align = "h")
```

***
**Self-similarity matrices**

A self-similarity matrix can explain the structure of the song. These matrices can be either based on chroma (pitch class) or timbre.

**Saddest song in the TOP2000: Who Wants to Live Forever**

The self-similarity matrices explain the structure of the song. In both matrices there are some clear distinctions visible between parts of the song. For example around 85 seconds, the moment when the chorus starts, there is a sharp change in both matrices.

**Everyone's favourite Eurovision band: ABBA**

This is a self-similarity matrix based on ABBA's song Dancing Queen. Both the chroma and timbre matrix show clearly that Dancing Queen consists of several parts with similar structures. The song starts with an intro that evolves into a part of the chorus. After this, from 43 seconds the first verse starts. In the timbre matrix this is the second purple square that follows the diagonal. The third purple box that starts at around 85 seconds indicates the start of the chorus. The chorus is followed by a shorter second verse, another chorus and an outro. The chroma matrix tells us that the song can be cut into even smaller sections, the chorus can for example be divided into two parts.

**Positions in TOP2000**

[Who Wants To Live Forever](https://open.spotify.com/track/3SGP8It5WDnCONyApJKRTJ?si=dba1813eb9644cd7): 1999: no. 30, 2009: no. 77, 2019: no. 74, 2022: no. 101

[Dancing Queen](https://open.spotify.com/track/0GjEhVFGZW8afUYGChu3Rr?si=8e4e72e8444f442f): 1999: no. 16, 2009: no. 70, 2019: no. 68, 2022: no. 44

### Key-changes are exciting! Keygrams {.storyboard}

```{r}
Beatles <-
  get_tidy_audio_analysis("5dfvhl9mJqgMVLNm3LAMnG") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Beatles_keygram <- Beatles |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Penny Lane \n(The Beatles)")

Radiohead <-
  get_tidy_audio_analysis("2nTsKOXIVGDf2iPeVQO2Gm") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Radiohead_keygram <- Radiohead |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Paranoid Android \n(Radiohead)")


Genesis <-
  get_tidy_audio_analysis("7bkjJHsfX2rebJ3KZLegGt") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Genesis_keygram <- Genesis |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Invisible Touch \n(Genesis)")


Backstreet <-
  get_tidy_audio_analysis("47BBI51FKFwOMlIiX6m8ya") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Backstreet_keygram <- Backstreet |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "B", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "I Want It That Way \n(Backstreet Boys)")

plot_grid(Beatles_keygram, Radiohead_keygram, Genesis_keygram, Backstreet_keygram, ncol = 2, nrow = 2)
```

***
**What is a keygram?**
lsjdlfksd

**Penny Lane**

The keygram is shown for Hey Jude by the Beatles. According to the keygram the key of the song changes a few times. it looks like the song starts with a short intro in A-minor and then moves to the key of F-major. After this there are two quick changes, the first of which is to Bb-minor or Bb-major. The keygram shows the same magnitude for these keys but it would make more sense that it's Bb-major because this key is closer related to the previous keys. After this the key goes back to F-major and then to the dominant of F, the C-major. The remaining part of the song the key changes between these two keys, the F-major and the C-major. Even though most of the key changes aren't that surprising, the fact that there are several changes makes it interesting to listen to. 

**Paranoid Android**

This song indeed makes me Paranoid, but in a good way!

**Invisible Touch**

sldfjsk

**I Want It That Way**

sdlfkjsldkf

**Positions in TOP2000**

[Penny Lane](https://open.spotify.com/track/1sjmKmR4u9xDeJHjDCn2bZ?si=a4924e3ad4b0479b): 1999: no. 266, 2009: no. 324, 2019: no. 377, 2022: no. 563

[Paranoid Android](https://open.spotify.com/track/2nTsKOXIVGDf2iPeVQO2Gm?si=169004f8f51240bc): 1999: -, 2009: -, 2019: no. 342, 2022: no. 423

[Invisible Touch](https://open.spotify.com/track/7bkjJHsfX2rebJ3KZLegGt?si=1c48ae0e1db54a40): 1999: -, 2009: no. 1738, 2019: no. 1982, 2022: no. 130

[I Want It That Way](https://open.spotify.com/track/47BBI51FKFwOMlIiX6m8ya?si=341df457e9f94861): 1999: -, 2009: no. 1569, 2019: no. 1014, 2022: no. 910

### Tempograms: Rainbow in the Sky and Killing in the Name {.storyboard}
```{r}
Rainbow <- get_tidy_audio_analysis("2MlqP1HzhitHfFXPXKumdB")

Rainbow_tempogram <- Rainbow |>
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = 'none') +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Rainbow In The Sky \n(Paul Elstak)") +
  theme_classic()

Killing <- get_tidy_audio_analysis("59WN2psjkt1tyaxjspN8fp")

Killing_tempogram <- Killing |>
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = 'none') +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Killing In The Name \n(Rage Against The Machine)") +
  theme_classic()

plot_grid(Rainbow_tempogram, Killing_tempogram, ncol = 1)
```

***
**What is a tempogram?**

A tempogram shows the BPM of a song over time. In this case the yellow lines show the BPM at a certain point in the song. Sometimes there is more than one yellow line visible, these 'extra' lines are tempo octaves.

**The tempogram of Rainbow in the Sky**

Rainbow in the Sky was released in 1995 but only entered the TOP2000 in 2015 at no. 765. Since, the song has been gaining a few places each year. Last edition, in 2022, the song ended up at the highest position yet, no. 366.

This is a tempogram of Rainbow in the Sky by DJ Paul Elstak. The tempogram shows a straight line throughtout the entire song around 360 BPM. At around 10 seconds and 75 seconds there are other yellow dots visible for 180 BPM, these are the tempo octaves. At 120 and 150 seconds there are also 'extra' short yellow lines in the tempogram. I personally don't have a good explanation for these lines that appear around 210 BPM. Rainbow in the Sky is an electronic track in the genre of happy hardcore. This explains the straight line in the tempogram, the electronically created beats happen in a very steady pace.

**The tempogram of Killing in the Name**

Just like Rainbow in the Sky, Killing in the Name was released (in 1992) many years before its introduction to the TOP2000 in 2011. Although the song entered at a relatively low position (no. 1454), the song has kept a steady position in the years following: ranging between no. 94 and no. 48. 

The tempogram of Killing in the Name by the band Rage Against the Machine looks very different compared to Rainbow in the Sky's tempogram. In this tempogram there is no straight yellow line. This means a few things. Firstly, Killing in the Name isn't an electronic track like Rainbow in the Sky. This means that the drummer needs to keep the exact same pace for some time, which can be hard. That makes the tempo in Killing in the Name automatically more dynamic and the yellow lines not as straight. A second reason for the bumpy lines could be the noise in the song. Everything in the song comes across as loud, the singing (or one could say almost screaming) and the lead guitar that has several solos for example. These parts don't have a very clear on beat tempo which might interfere with the tempo of the drums. The final reason for why there isn't a straight line, are the tempo changes. These changes are quite obvious when you listen to the song. A clear example of one of these changes is at 2 min. 25 (145 seconds). The song switches here from the chorus to the second verse. The chorus has strong vocals and a heavy guitar with a slightly faster beat than the verse which has the characteristic guitar riff with softer vocals.

**Positions in TOP2000**

[Rainbow in the Sky](https://open.spotify.com/track/2MlqP1HzhitHfFXPXKumdB?si=e2bdad09cfb343b4): 1999: -, 2009: -, 2019: no. 386, 2022: no. 366

[Killing In The Name](https://open.spotify.com/track/59WN2psjkt1tyaxjspN8fp?si=00be500cee6e4ae7): 1999: -, 2009: -, 2019: no. 60, 2022: no. 48

### Timbre in the Top 2000 {.storyboard}
```{r}
Top1999timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0qSHbyaiZbhacDdIegMoBR"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2009timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "6BJbzcSvOunQpVCJuBLxEW"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2019timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "1MaaUHHVuXbmrDhoUCDDcL"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2022timbre <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "4U5UXciYphLDZAIgjdz50v"
  ) |>
  slice(1:100) |>
  add_audio_analysis()
Top2000timbre <-
  bind_rows(
   Top1999timbre |> mutate(year = "1999"),
   Top2009timbre |> mutate(year = "2009"),
   Top2019timbre |> mutate(year = "2019"),
   Top2022timbre |> mutate(year = "2022")
  )
```

```{r, fig.width=10, fig.height=4}
Top2000timbre |>
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) |>
  select(year, timbre) |>
  compmus_gather_timbre() |>
  ggplot(aes(x = basis, y = value, fill = year)) +
  geom_violin() +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Year")
```

***
This plot shows the timbre values from 3 years of the TOP 2000. Only the first 100 songs of the playlists are used for this plot. A few timbre coefficients show differences between the four years. For example c02, c04, c06 and c012. In c06 the year of 2009 stands out, the violin has a much longer shape compared to the other years. The same is true for c12 where 1999 has a longer and different shape than the other years. The violins of 2019 and 2022 are very alike for all of the timbre coefficients. This might be because there are only 3 years in between. It means that the first 100 songs in these playlists "sound" relatively the same.

### Loudness, tempo and duration {.storyboard}
```{r}
Top2000timbreplotly <- Top2000timbre |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = loudness,
      text = track.name
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  facet_wrap(~year) +
  theme_light() +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    size = "Duration (min)",
    colour = "Volume (dBFS)"
  )

ggplotly(Top2000timbreplotly)
```

***
**The features**
lskdfjlsdkf

**The plot**
This plot shows the loudness tempo and duration of the first 100 songs in four years in the TOP2000.

### Dendrogram TOP2000 {.storyboard}
```{r, fig.width=11, fig.height=4}
Dendro1999 <-
  get_playlist_audio_features("1999", "6VEGxOyJCx6WYTXJIBy0tb") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro1999_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro1999
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro1999 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro1999_dist <- dist(Dendro1999_juice, method = "euclidean")

Dendro1999_dist |> 
  hclust(method = "complete") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()
```

***
Dendrogram blablabla

### Dendrogram 2009
```{r, fig.width=11, fig.height=4}
Dendro2009 <-
  get_playlist_audio_features("2009", "0qoaHjMRoMN7v9A56R5yYB") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro2009_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro2009
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro2009 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro2009_dist <- dist(Dendro2009_juice, method = "euclidean")

Dendro2009_dist |> 
  hclust(method = "complete") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()

```

***
2009: Metallica One weg

### Dendrogram 2019
```{r, fig.width=11, fig.height=4}
Dendro2019 <-
  get_playlist_audio_features("2019", "3qlSwTObXFlCAPg6HMOT7h") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro2019_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro2019
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro2019 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro2019_dist <- dist(Dendro2019_juice, method = "euclidean")

Dendro2019_dist |> 
  hclust(method = "complete") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()
```

***
2019: Jeff Buckley Hallulajah weg

2019: One Mary J Blige and U2 weg

2019: Metallica One weg

### Dendrogram 2022
```{r, fig.width=11, fig.height=4}
Dendro2022 <-
  get_playlist_audio_features("2022", "3mC8WmcqnXTtM0A4hOKyNc") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

Dendro2022_juice <-
  recipe(
    track.name ~
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Dendro2022
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(Dendro2022 |> mutate(track.name = str_trunc(track.name, 25))) |>
  juice() |>
  column_to_rownames("track.name")

Dendro2022_dist <- dist(Dendro2022_juice, method = "euclidean")

Dendro2022_dist |> 
  hclust(method = "complete") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()
```


***
2022: One Mary J Blige and U2 weg

2022: Metallica One weg

2022: The Sound of Silence Disturbed weg

Conclusion
=================================================
I have analysed a lot of different types of songs from my corpus. 


